{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook helps us view the results on the training and validation set taking the best model round saved based on its name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "import model_zoo\n",
    "import data_freiburg_numpy_to_hdf5\n",
    "from utils import make_dir_safely\n",
    "from scipy.special import softmax\n",
    "import h5py\n",
    "\n",
    "from losses import compute_dice"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load saved model\n",
    "loss = \"dice\"\n",
    "out_channels = 2\n",
    "in_channels = 4\n",
    "run = 1\n",
    "note = '_full_run_bern_full'\n",
    "cut_z = False # True/3\n",
    "da = 0.0\n",
    "#model_path = f'/usr/bmicnas02/data-biwi-01/jeremy_students/lschlyter/CNN-segmentation/logdir/unet3d_da_{da}nchannels{in_channels}_r{run}_loss_{loss}_cut_z_{cut_z}{note}'\n",
    "model_path = '/usr/bmicnas02/data-biwi-01/jeremy_students/lschlyter/CNN-segmentation/logdir/unet3d_da_0.0nchannels4_r1_loss_dice_cut_z_False_full_run_only_w_labels_e80_lr_1e-3_AdamW_val_40'\n",
    "best_model_path = os.path.join(model_path, list(filter(lambda x: 'best' in x, os.listdir(model_path)))[-1])\n",
    "print(best_model_path)\n",
    "model = model_zoo.UNet(in_channels, out_channels)\n",
    "model.load_state_dict(torch.load(best_model_path, map_location=torch.device('cpu')));\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bern data\n",
    "# This has already done Bern_numpy_to_hdf5.py\n",
    "basepath = \"/usr/bmicnas02/data-biwi-01/jeremy_students/data/inselspital/kady\"\n",
    "bern_tr = h5py.File(basepath + '/size_40_bern_images_and_labels_from_101_to_121.hdf5','r')\n",
    "bern_vl = h5py.File(basepath + '/size_40_bern_images_and_labels_from_122_to_127.hdf5','r')\n",
    "\n",
    "images_tr = bern_tr['images_train']#[:]\n",
    "labels_tr = bern_tr['labels_train']#[:]\n",
    "images_vl = bern_vl['images_validation']#[:]\n",
    "labels_vl = bern_vl['labels_validation']#[:]\n",
    "\n",
    "\n",
    "#images_tr = bern_tr['images_train'][:]\n",
    "#labels_tr = bern_tr['labels_train'][:]\n",
    "#images_vl = bern_vl['images_validation'][:]\n",
    "#labels_vl = bern_vl['labels_validation'][:]        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cut_z != False:\n",
    "    keep_indices_tr = np.where(bern_tr['alias'][:] ==0)[0]\n",
    "    keep_indices_vl = np.where(bern_vl['alias'][:] ==0)[0]\n",
    "    images_tr = images_tr[keep_indices_tr]\n",
    "    labels_tr = labels_tr[keep_indices_tr]\n",
    "    images_vl = images_vl[keep_indices_vl]\n",
    "    labels_vl = labels_vl[keep_indices_vl]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_tr.shape, labels_tr.shape, images_vl.shape, labels_vl.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute dice loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_minibatches_validation(images, labels, batch_size):\n",
    "    \"\"\"\n",
    "    Function to create mini batches from the dataset of a certain batch size\n",
    "    :param images: input images\n",
    "    :param labels: labels\n",
    "    :param batch_size: batch size\n",
    "    :return: mini batches\"\"\"\n",
    "    assert len(images) == len(labels)\n",
    "    \n",
    "    # Generate randomly selected slices in each minibatch\n",
    "\n",
    "    n_images = images.shape[0]\n",
    "    random_indices = np.arange(n_images)\n",
    "    np.random.shuffle(random_indices)\n",
    "\n",
    "    # Use only fraction of the batches in each epoch\n",
    "\n",
    "    for b_i in range(0, n_images, batch_size):\n",
    "\n",
    "        if b_i + batch_size > n_images:\n",
    "            continue\n",
    "\n",
    "\n",
    "        # HDF5 requires indices to be in increasing order\n",
    "        batch_indices = np.sort(random_indices[b_i:b_i+batch_size])\n",
    "\n",
    "        X = images[batch_indices, ...]\n",
    "        y = labels[batch_indices, ...]\n",
    "        \n",
    "        # ===========================\n",
    "        # check if the velocity fields are to be used for the segmentation...\n",
    "        # ===========================\n",
    "        if in_channels == 1:\n",
    "            X = X[..., 1:2]\n",
    "        \n",
    "        yield X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_score(images_set, labels_set, batch_size = 4):\n",
    "        dice_score = 0\n",
    "        for n_batch, batch in enumerate(iterate_minibatches_validation(images_set, labels_set, batch_size = batch_size)):\n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                        inputs, labels = batch\n",
    "                \n",
    "                        # From numpy.ndarray to tensors\n",
    "                \n",
    "                        # Input (batch_size, x,y,t,channel_number)\n",
    "                        inputs = torch.from_numpy(inputs)\n",
    "                        # Input (batch_size, channell,x,y,t)\n",
    "                        inputs.transpose_(1,4).transpose_(2,4).transpose_(3,4)\n",
    "                        # Labels (batch,size, x,y,t)\n",
    "                \n",
    "                        #inputs = inputs.to(device)\n",
    "                        labels = torch.from_numpy(labels)#.to(device)\n",
    "                        labels = torch.nn.functional.one_hot(labels.long(), num_classes = out_channels)\n",
    "                        labels = labels.transpose(1,4).transpose(2,4).transpose(3,4)\n",
    "                        \n",
    "                        \n",
    "                        logits = model(inputs.float())\n",
    "                        \n",
    "                        _, mean_dice,_= compute_dice(logits, labels)\n",
    "                        \n",
    "                        dice_score += mean_dice  \n",
    "        return dice_score, n_batch\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training dice\")\n",
    "dice_score_tr, n_batch_tr = dice_score(images_tr, labels_tr, batch_size = 2)\n",
    "print(\"Total average dice score: \", dice_score_tr/(n_batch_tr+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Validation dice\")\n",
    "dice_score_vl, n_batch_vl = dice_score(images_vl, labels_vl, batch_size = 2)\n",
    "print(\"Total average dice score: \", dice_score_vl/(n_batch_vl+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 48\n",
    "np.random.seed(0)\n",
    "#inputs = images_vl[np.sort(np.random.randint(len(images_vl), size = batch_size))]\n",
    "inputs = images_vl[0:batch_size]\n",
    "np.random.seed(0)\n",
    "labels = labels_vl[0:batch_size]\n",
    "#labels = labels_vl[np.sort(np.random.randint(len(images_vl), size = batch_size))]\n",
    "\n",
    "inputs = torch.from_numpy(inputs)\n",
    "# Input (batch_size, channell,x,y,z)\n",
    "inputs.transpose_(1,4).transpose_(2,4).transpose_(3,4)\n",
    "labels = torch.from_numpy(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.array([]).reshape(0, 2,144, 112,48)\n",
    "for i in range(batch_size):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        #pred = model(inputs[i*batch_size//8:(i+1)*batch_size//8])\n",
    "        pred = model(inputs[i:i+1])\n",
    "        preds = np.vstack([preds, pred.detach().numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prediction = softmax(preds, axis=1).argmax(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "def plot_time(t = 0):\n",
    "    fig, axs = plt.subplots(9,9, figsize=(15, 15), facecolor='w', edgecolor='k');\n",
    "    img = 0\n",
    "    for i, ax in enumerate(axs.reshape(-1)):\n",
    "        \n",
    "        if i%2 == 0:\n",
    "            ax.imshow(prediction[img,:,:,t])\n",
    "            \n",
    "\n",
    "        else:\n",
    "            ax.imshow(labels[img,:,:,t])   \n",
    "            img = img + 1 \n",
    "        #print(img)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_time(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization the outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_on = \"validation\" # training/validation\n",
    "model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_files = os.listdir(model_path + f'/results/visualization/{viz_on}/')\n",
    "image_number = 10\n",
    "list_files[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_filter = list(filter(lambda x: f'_image_{image_number}' in x, list_files))\n",
    "image_filter[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_filter = list(filter(lambda x: f'_image_{image_number}' in x, list_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for best model STEP\n",
    "step = 1000\n",
    "pred = np.load(os.path.join(model_path,f'results/visualization/{viz_on}', list(filter(lambda x: f'_{step}' in x, image_filter))[0]))\n",
    "gt = np.load(os.path.join(model_path,f'results/visualization/{viz_on}', list(filter(lambda x: f'_{step}' in x, image_filter))[1]))\n",
    "input = np.load(os.path.join(model_path,f'results/visualization/{viz_on}', list(filter(lambda x: f'_{step}' in x, image_filter))[2]))\n",
    "np.where(gt ==1), np.where(pred ==1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "def plot_batches(array, input_image = False):\n",
    "\n",
    "    time_slice = 20\n",
    "    if input_image:\n",
    "        fig, axs = plt.subplots(2, 4, figsize=(6,6))\n",
    "        for n, ax in enumerate(axs.reshape(-1)):\n",
    "            ax.imshow(array[n,0,:,:,time_slice])\n",
    "        plt.show()\n",
    "    else:\n",
    "        fig, axs = plt.subplots(2, 4, figsize=(6,6))\n",
    "        for n, ax in enumerate(axs.reshape(-1)):\n",
    "            ax.imshow(array[n,:,:,time_slice])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_batches(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_batches(input, input_image = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_batches(gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt.shape, input.shape, pred.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "def presentation_viz(input, gt, pred, time, save_path, n_channels = 4, batch = 8):\n",
    "    # Create directory if it does not exist\n",
    "    make_dir_safely(save_path)\n",
    "    if n_channels == 4:\n",
    "        h = 18\n",
    "    else:\n",
    "        h = 7\n",
    "    \n",
    "    fig, axs = plt.subplots(2+n_channels, batch, figsize = (18,h))\n",
    "    nbatch = 0\n",
    "    n_chan = n_channels\n",
    "    ax = axs.reshape(-1)\n",
    "    axes_index = 0\n",
    "    for chan in range(n_channels):\n",
    "        \n",
    "        for i in range(batch):\n",
    "            \n",
    "            ax[axes_index].imshow(input[i, n_channels - n_chan, :, :, time])\n",
    "            ax[axes_index].set_title(f\"n_{i}_ch:{n_channels - n_chan}_t_{time}\", fontsize = 10)\n",
    "            axes_index += 1\n",
    "        n_chan -= 1\n",
    "    for i in range(batch):\n",
    "        ax[axes_index].imshow(pred[i, :,:, time])\n",
    "        ax[axes_index].set_title(f\"n_{i}_pred_t_{time}\", fontsize = 10)\n",
    "        axes_index +=1\n",
    "    for i in range(batch):\n",
    "        ax[axes_index].imshow(gt[i, :,:, time])\n",
    "        ax[axes_index].set_title(f\"n_{i}_gt_t_{time}\", fontsize = 10)\n",
    "        axes_index +=1\n",
    "    #plt.savefig(os.path.join(save_path, f\"random_batch_t_{time}.png\"), bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_viz = model_path + f\"/results/visualization/notebook_viz/{viz_on}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "presentation_viz(input, gt, pred, time = 3, save_path= save_viz, n_channels = in_channels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    debug_in = np.load(model_path + \"/inputs_train_batch.npy\")\n",
    "    debug_label = np.load(model_path + \"/labels_train_batch.npy\")\n",
    "    slice_ = 0\n",
    "    print(slice_)\n",
    "    %matplotlib inline\n",
    "    plt.imshow(debug_in[slice_, :,:, 3,1])\n",
    "    plt.show()\n",
    "    plt.imshow(debug_in[slice_, :,:, 3,0])\n",
    "    plt.imshow(debug_label[slice_, :,:, 3], alpha= 0.1)\n",
    "    slice_ +=1 \n",
    "    plt.show()\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hpc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
