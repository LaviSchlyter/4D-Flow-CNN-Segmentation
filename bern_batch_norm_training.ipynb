{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from scipy.special import softmax\n",
    "import sys\n",
    "import model_zoo\n",
    "import data_freiburg_numpy_to_hdf5\n",
    "from utils import make_dir_safely, normalize_image\n",
    "from losses import compute_dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bern data\n",
    "# This has already done Bern_numpy_to_hdf5.py\n",
    "basepath = \"/usr/bmicnas02/data-biwi-01/jeremy_students/data/inselspital/kady\"\n",
    "bern_tr = h5py.File(basepath + '/bern_images_and_labels_from_101_to_104.hdf5','r')\n",
    "bern_vl = h5py.File(basepath + '/bern_images_and_labels_from_105_to_106.hdf5','r')\n",
    "images_tr = bern_tr['images_train']\n",
    "labels_tr = bern_tr['labels_train']\n",
    "images_vl = bern_vl['images_validation']\n",
    "labels_vl = bern_vl['labels_validation']        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load saved model\n",
    "loss = \"dice\"\n",
    "out_channels = 2\n",
    "in_channels = 4\n",
    "run = 1\n",
    "note = '_full_run_fine_tune_Bern_lr_0.5e-3_scheduler_e50'\n",
    "cut_z = 3\n",
    "da = 0.0\n",
    "model_path = f'/usr/bmicnas02/data-biwi-01/jeremy_students/lschlyter/CNN-segmentation/logdir/unet3d_da_{da}nchannels{in_channels}_r{run}_loss_{loss}_cut_z_{cut_z}{note}'\n",
    "#model_path = f'/usr/bmicnas02/data-biwi-01/jeremy_students/lschlyter/CNN-segmentation/logdir/unet3d_da_{da}nchannels{in_channels}_r{run}_loss_{loss}_cut_z_{cut_z}{note}'\n",
    "#model_path = f'/usr/bmicnas02/data-biwi-01/jeremy_students/lschlyter/CNN-segmentation/logdir/unet3d_da_{da}nchannels{in_channels}_r_phase_dice_cut_z_5_debug'\n",
    "#model_path = \"/usr/bmicnas02/data-biwi-01/jeremy_students/lschlyter/CNN-segmentation/logdir/unet3d_da_0.0nchannels1_r_DEBUG_LOSS_phase_dice_cut_z_0\"\n",
    "best_model_path = os.path.join(model_path, list(filter(lambda x: 'best' in x, os.listdir(model_path)))[-1])\n",
    "print(best_model_path)\n",
    "model = model_zoo.UNet(in_channels, out_channels);\n",
    "model.load_state_dict(torch.load(best_model_path, map_location=torch.device('cpu')));\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here you should do the cutting... \n",
    "def cut_z_slices(images, labels, n_cut):\n",
    "    n_data = images.shape[0]\n",
    "    index = np.arange(n_data)\n",
    "    # We know we have 32 slices\n",
    "    # First dim is the number of patients\n",
    "    index_shaped = index.reshape(-1, 32)\n",
    "    index_keep = index_shaped[:, n_cut:-n_cut].flatten()\n",
    "    return images[index_keep], labels[index_keep]\n",
    "\n",
    "if cut_z != 0:\n",
    "    images_tr, labels_tr = cut_z_slices(images_tr, labels_tr, n_cut = cut_z)\n",
    "    images_vl, labels_vl = cut_z_slices(images_vl, labels_vl, n_cut = cut_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_tr.shape, labels_tr.shape, images_vl.shape, labels_vl.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_minibatches_validation(images, labels, batch_size):\n",
    "    \"\"\"\n",
    "    Function to create mini batches from the dataset of a certain batch size\n",
    "    :param images: input images\n",
    "    :param labels: labels\n",
    "    :param batch_size: batch size\n",
    "    :return: mini batches\"\"\"\n",
    "    assert len(images) == len(labels)\n",
    "    \n",
    "    # Generate randomly selected slices in each minibatch\n",
    "\n",
    "    n_images = images.shape[0]\n",
    "    random_indices = np.arange(n_images)\n",
    "    np.random.shuffle(random_indices)\n",
    "\n",
    "    # Use only fraction of the batches in each epoch\n",
    "\n",
    "    for b_i in range(0, n_images, batch_size):\n",
    "\n",
    "        if b_i + batch_size > n_images:\n",
    "            continue\n",
    "\n",
    "\n",
    "        # HDF5 requires indices to be in increasing order\n",
    "        batch_indices = np.sort(random_indices[b_i:b_i+batch_size])\n",
    "\n",
    "        X = images[batch_indices, ...]\n",
    "        y = labels[batch_indices, ...]\n",
    "        \n",
    "        # ===========================\n",
    "        # check if the velocity fields are to be used for the segmentation...\n",
    "        # ===========================\n",
    "        if in_channels == 1:\n",
    "            X = X[..., 1:2]\n",
    "        \n",
    "        yield X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_score_bern(images_set, labels_set, batch_size = 4):\n",
    "        dice_score = 0\n",
    "        for n_batch, batch in enumerate(iterate_minibatches_validation(images_set, labels_set, batch_size = batch_size)):\n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                        inputs, labels = batch\n",
    "                \n",
    "                        # From numpy.ndarray to tensors\n",
    "                \n",
    "                        # Input (batch_size, x,y,t,channel_number)\n",
    "                        inputs = torch.from_numpy(inputs)\n",
    "                        # Input (batch_size, channell,x,y,t)\n",
    "                        inputs.transpose_(1,4).transpose_(2,4).transpose_(3,4)\n",
    "                        # Labels (batch,size, x,y,t)\n",
    "                \n",
    "                        #inputs = inputs.to(device)\n",
    "                        labels = torch.from_numpy(labels)#.to(device)\n",
    "                        labels = torch.nn.functional.one_hot(labels.long(), num_classes = out_channels)\n",
    "                        labels = labels.transpose(1,4).transpose(2,4).transpose(3,4)\n",
    "                        if labels.shape[0] < batch_size:\n",
    "                                continue\n",
    "                        \n",
    "                        logits = model(inputs.float())\n",
    "                        \n",
    "                        _, mean_dice,_= compute_dice(logits, labels)\n",
    "                        \n",
    "                        dice_score += mean_dice  \n",
    "        return dice_score, n_batch\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_vl.shape, labels_vl.shape, images_tr.shape, labels_tr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training dice\")\n",
    "dice_score_tr, n_batch_tr = dice_score_bern(images_tr, labels_tr, batch_size = 4)\n",
    "print(\"Total average dice score: \", dice_score_tr/(n_batch_tr+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dice_score_tr/(n_batch_tr+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Validation dice\")\n",
    "dice_score_vl, n_batch_vl = dice_score_bern(images_vl, labels_vl, batch_size = 4)\n",
    "print(\"Total average dice score: \", dice_score_vl/(n_batch_vl+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dice_score_vl/(n_batch_vl+1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_on = \"validation\" # training/validation\n",
    "best_model_path"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "list_files = os.listdir(model_path + f'/results/visualization/{viz_on}/')\n",
    "image_number = 0\n",
    "image_filter = list(filter(lambda x: f'_image_{image_number}' in x, list_files))\n",
    "image_filter[-5:]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Check for best model STEP\n",
    "step = 800\n",
    "pred = np.load(os.path.join(model_path,f'results/visualization/{viz_on}', list(filter(lambda x: f'_{step}' in x, image_filter))[0]))\n",
    "gt = np.load(os.path.join(model_path,f'results/visualization/{viz_on}', list(filter(lambda x: f'_{step}' in x, image_filter))[1]))\n",
    "input = np.load(os.path.join(model_path,f'results/visualization/{viz_on}', list(filter(lambda x: f'_{step}' in x, image_filter))[2]))\n",
    "np.where(gt ==1), np.where(pred ==1)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pred.shape, gt.shape, input.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%matplotlib inline\n",
    "def plot_batches(array, input_image = False):\n",
    "\n",
    "    time_slice = 0\n",
    "    if input_image:\n",
    "        fig, axs = plt.subplots(2, 4, figsize=(6,6))\n",
    "        for n, ax in enumerate(axs.reshape(-1)):\n",
    "            ax.imshow(array[n,0,:,:,time_slice])\n",
    "        plt.show()\n",
    "    else:\n",
    "        fig, axs = plt.subplots(2, 4, figsize=(6,6))\n",
    "        for n, ax in enumerate(axs.reshape(-1)):\n",
    "            ax.imshow(array[n,:,:,time_slice])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plot_batches(input, input_image = True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plot_batches(pred)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plot_batches(gt)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plot_batches(input, input_image = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(images_vl.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(images_vl.shape[0])\n",
    "indexes = np.arange(images_vl.shape[0]//2,images_vl.shape[0] , 1)\n",
    "\n",
    "inputs = images_vl[indexes]\n",
    "labels = labels_vl[indexes]\n",
    "print(inputs.shape, labels.shape)\n",
    "inputs = torch.from_numpy(inputs)\n",
    "# Input (batch_size, channell,x,y,z)\n",
    "inputs.transpose_(1,4).transpose_(2,4).transpose_(3,4)\n",
    "labels = torch.from_numpy(labels)\n",
    "print(inputs.shape, labels.shape)\n",
    "preds = np.array([]).reshape(0, 2,144, 112,48)\n",
    "for i in range(inputs.shape[0]):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        pred = model(inputs[None, i, :, :,:,:])\n",
    "        preds = np.vstack([preds, pred.detach().numpy()])\n",
    "        prediction = softmax(preds, axis=1).argmax(axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_axes = np.transpose(prediction, (1, 2, 0, 3))\n",
    "\n",
    "np.save('prediction_validation_0_full_run_fine_tune_Bern_lr_0.5e-3_e50.npy', prediction_axes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_n = 0\n",
    "# By patient\n",
    "batch_size = 9\n",
    "indexes_z_slices =np.arange(0, (32 - 2*cut_z), (32 - cut_z)//8)\n",
    "indexes =np.arange((32 -2 *cut_z)*patient_n, (32 - 2*cut_z)*(patient_n + 1), (32 - cut_z)//8)\n",
    "inputs = images_vl[indexes]\n",
    "labels = labels_vl[indexes]\n",
    "\n",
    "print(inputs.shape, labels.shape)\n",
    "inputs = torch.from_numpy(inputs)\n",
    "# Input (batch_size, channell,x,y,z)\n",
    "inputs.transpose_(1,4).transpose_(2,4).transpose_(3,4)\n",
    "labels = torch.from_numpy(labels)\n",
    "print(inputs.shape, labels.shape)\n",
    "n_range = 9\n",
    "preds = np.array([]).reshape(0, 2,144, 112,48)\n",
    "for i in range(n_range):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        pred = model(inputs[i*batch_size//n_range:(i+1)*batch_size//n_range])\n",
    "        preds = np.vstack([preds, pred.detach().numpy()])\n",
    "        prediction = softmax(preds, axis=1).argmax(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "def presentation_viz_by_patient(input, gt, pred, time, save_path, note_save, indexes, n_channels = 4):\n",
    "    z_slices = np.arange(0, len(indexes))\n",
    "    \n",
    "    # Create directory if it does not exist\n",
    "    if save_path is not None:\n",
    "        make_dir_safely(save_path)\n",
    "    if n_channels == 4:\n",
    "        h = 18\n",
    "    else:\n",
    "        h = 7\n",
    "    \n",
    "    fig, axs = plt.subplots(2+n_channels, len(z_slices), figsize = (18,h))\n",
    "    nbatch = 0\n",
    "    n_chan = n_channels\n",
    "    ax = axs.reshape(-1)\n",
    "    axes_index = 0\n",
    "    for chan in range(n_channels):\n",
    "        \n",
    "        for i, z_slice in enumerate(indexes):\n",
    "            \n",
    "            ax[axes_index].imshow(input[i, n_channels - n_chan, :, :, time])\n",
    "            ax[axes_index].set_title(f\"z_{z_slice}_ch:{n_channels - n_chan}_t_{time}\", fontsize = 10)\n",
    "            axes_index += 1\n",
    "        n_chan -= 1\n",
    "    for i, z_slice in enumerate(indexes):\n",
    "        ax[axes_index].imshow(pred[i, :,:, time])\n",
    "        ax[axes_index].set_title(f\"z_{z_slice}_pred_t_{time}\", fontsize = 10)\n",
    "        axes_index +=1\n",
    "    for i, z_slice in enumerate(indexes):\n",
    "        ax[axes_index].imshow(gt[i, :,:, time])\n",
    "        ax[axes_index].set_title(f\"z_{z_slice}_gt_t_{time}\", fontsize = 10)\n",
    "        axes_index +=1\n",
    "    plt.savefig(save_path + f\"{note_save}_t_{time}.png\", bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_viz = model_path + f\"/results/visualization/notebook_viz/{viz_on}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "presentation_viz_by_patient(input=inputs, gt=labels, pred=prediction, time=3, save_path = save_viz, n_channels = in_channels, indexes = indexes_z_slices,note_save = \"patient_0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seg_net",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
