{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import SimpleITK as sitk\n",
    "from scipy import interpolate\n",
    "\n",
    "from back_transform_utils import crop_or_pad_Bern_new, skeleton_points\n",
    "from utils import normalize_image_new\n",
    "\n",
    "from skimage.morphology import skeletonize_3d, dilation, cube\n",
    "\n",
    "from utils_centerline import interpolate_and_slice\n",
    "from mayavi import mlab as mlab\n",
    "from utils_centerline import extract_slice_from_sitk_image\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_or_pad_normal_slices(data, new_shape):\n",
    "    \n",
    "    processed_data = np.zeros(new_shape)\n",
    "    # axis 0 is the x-axis and we crop from top since aorta is at the bottom\n",
    "    # axis 1 is the y-axis and we crop equally from both sides\n",
    "    # axis 2 is the z-axis and we crop from the right (end of the image) since aorta is at the left\n",
    "    delta_axis0 = data.shape[0] - new_shape[0]\n",
    "    \n",
    "    if len(new_shape) == 5: # Image\n",
    "        # The x is always cropped, y always padded, z_cropped\n",
    "        try:\n",
    "            processed_data[:, :data.shape[1],:,:data.shape[3],... ] = data[delta_axis0:,:new_shape[1], :new_shape[2],...]\n",
    "        except:\n",
    "            processed_data[:, :data.shape[1],:,:data.shape[3],... ] = data[delta_axis0:,:new_shape[1], :new_shape[2],:new_shape[3],...]\n",
    "\n",
    "    if len(new_shape) == 4: # Label\n",
    "        # The x is always cropped, y always padded, z_cropped\n",
    "        try:\n",
    "            processed_data[:, :data.shape[1],:,:data.shape[3],... ] = data[delta_axis0:,:new_shape[1], :new_shape[2],...]\n",
    "        except:\n",
    "            processed_data[:, :data.shape[1],:,:data.shape[3],... ] = data[delta_axis0:,:new_shape[1], :new_shape[2],:new_shape[3],...]\n",
    "    return processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# The output is bascially the anomaly score \u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/usr/bmicnas02/data-biwi-01/jeremy_students/lschlyter/4dflowmri_anomaly_detection/Results/Evaluation/cond_vae/masked_slice/20230712-1205_cond_vae_masked_slice_SSL_lr1.000e-03-e1200-bs8-gf_dim8-daFalse-n_experts3_2Dslice_decreased_interpolation_factor_cube_3/test/outputs/MACDAVD_311__anomaly_scores.npy\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m seg_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/usr/bmicnas02/data-biwi-01/jeremy_students/data/inselspital/kady/final_segmentations/controls/seg_MACDAVD_101_.npy\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m img_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/usr/bmicnas02/data-biwi-01/jeremy_students/data/inselspital/kady/preprocessed/controls/numpy/MACDAVD_101_.npy\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "# The output is bascially the anomaly score \n",
    "output = np.load(\"/usr/bmicnas02/data-biwi-01/jeremy_students/lschlyter/4dflowmri_anomaly_detection/Results/Evaluation/cond_vae/masked_slice/20230712-1205_cond_vae_masked_slice_SSL_lr1.000e-03-e1200-bs8-gf_dim8-daFalse-n_experts3_2Dslice_decreased_interpolation_factor_cube_3/test/outputs/MACDAVD_311__anomaly_scores.npy\")\n",
    "seg_path = \"/usr/bmicnas02/data-biwi-01/jeremy_students/data/inselspital/kady/final_segmentations/controls/seg_MACDAVD_101_.npy\"\n",
    "img_path = f'/usr/bmicnas02/data-biwi-01/jeremy_students/data/inselspital/kady/preprocessed/controls/numpy/MACDAVD_101_.npy'\n",
    "output_reshaped = np.repeat(output.transpose(2,3,0,4,1), 4, axis=4)\n",
    "\n",
    "# Load the geometry information of the slices \n",
    "geometry_dict = np.load(\"/usr/bmicnas02/data-biwi-01/jeremy_students/lschlyter/4dflowmri_anomaly_detection/data/geometry_for_backtransformation/MACDAVD_101_.npy\", allow_pickle=True).item()\n",
    "\n",
    "output.shape, output_reshaped.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = np.load(img_path)\n",
    "segmented_original = np.load(seg_path)\n",
    "# Enlarge the segmentation slightly to be sure that there are no cutoffs of the aorta\n",
    "time_steps = segmented_original.shape[3]\n",
    "segmented = dilation(segmented_original[:,:,:,3], cube(3))\n",
    "temp_for_stack = [segmented for i in range(time_steps)]\n",
    "segmented = np.stack(temp_for_stack, axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((160, 110, 60, 23, 4), (160, 110, 60, 23))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape, segmented.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to pad it back to original 36,36,64 - it was down to 32 for network reasons \n",
    "\n",
    "def expand_normal_slices(data, original_shape):\n",
    "    \n",
    "    # Create an array of zeros with the original shape\n",
    "    expanded_data = np.zeros(original_shape)\n",
    "\n",
    "    # Compute the difference in the first two dimensions\n",
    "    delta_axis0 = original_shape[0] - data.shape[0]\n",
    "    delta_axis1 = original_shape[1] - data.shape[1]\n",
    "    \n",
    "    # Place the cropped data back into the array\n",
    "    expanded_data[delta_axis0:,:data.shape[1], :data.shape[2],:data.shape[3],... ] = data\n",
    "\n",
    "    return expanded_data\n",
    "\n",
    "output_reshaped_again = expand_normal_slices(output_reshaped, [36,36,64,24,4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/bmicnas02/data-biwi-01/jeremy_students/lschlyter/CNN-segmentation/back_transform_utils.py:27: FutureWarning: `selem` is a deprecated argument name for `binary_erosion`. It will be removed in version 1.0. Please use `footprint` instead.\n",
      "  avg = binary_erosion(avg, selem=np.ones((erosion_k, erosion_k,erosion_k)))\n",
      "/usr/bmicnas02/data-biwi-01/jeremy_students/lschlyter/CNN-segmentation/back_transform_utils.py:28: FutureWarning: `selem` is a deprecated argument name for `dilation`. It will be removed in version 1.0. Please use `footprint` instead.\n",
      "  avg = dilation(avg, selem=np.ones((dilation_k, dilation_k,dilation_k)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channel 0\n",
      "Channel 1\n",
      "Channel 2\n",
      "Channel 3\n"
     ]
    }
   ],
   "source": [
    "# Shape of the sliced images\n",
    "common_image_shape = [36, 36, 64, 24, 4] # [x, y, z, t, num_channels]\n",
    "end_shape = [32, 32, 64, 24, 4]\n",
    "image = np.load(img_path)\n",
    "segmented_original = np.load(seg_path)\n",
    "# Enlarge the segmentation slightly to be sure that there are no cutoffs of the aorta\n",
    "time_steps = segmented_original.shape[3]\n",
    "segmented = dilation(segmented_original[:,:,:,3], cube(3))\n",
    "temp_for_stack = [segmented for i in range(time_steps)]\n",
    "segmented = np.stack(temp_for_stack, axis=3)\n",
    "\n",
    "# normalize image to -1 to 1\n",
    "image = normalize_image_new(image)\n",
    "seg_shape = list(segmented.shape)\n",
    "seg_shape.append(image.shape[-1])\n",
    "#image_cropped = crop_or_pad_Bern_new(image, seg_shape)\n",
    "image_cropped = image\n",
    "temp_images_intensity = image_cropped[:,:,:,:,0] * segmented # change these back if it works\n",
    "temp_images_vx = image_cropped[:,:,:,:,1] * segmented\n",
    "temp_images_vy = image_cropped[:,:,:,:,2] * segmented\n",
    "temp_images_vz = image_cropped[:,:,:,:,3] * segmented\n",
    "\n",
    "## recombine the images\n",
    "image = np.stack([temp_images_intensity,temp_images_vx,temp_images_vy,temp_images_vz], axis=4)\n",
    "cnn_predictions = True\n",
    "\n",
    "\n",
    "\n",
    "if cnn_predictions:\n",
    "    points_ = skeleton_points(segmented_original, dilation_k = 0)\n",
    "    points_dilated = skeleton_points(segmented_original, dilation_k = 4,erosion_k = 4)\n",
    "else:\n",
    "    points_ = skeleton_points(segmented_original, dilation_k = 0)\n",
    "    points_dilated = skeleton_points(segmented_original, dilation_k = 2,erosion_k = 2)\n",
    "points_all = points_dilated.copy()     \n",
    "\n",
    "\n",
    "points = points_all[np.where(points_all[:,1]<60)]\n",
    "points = points[np.where(points[:,0]<90)]\n",
    "\n",
    "\n",
    "# Order the points in ascending order with x\n",
    "points = points[points[:,0].argsort()[::-1]]\n",
    "\n",
    "temp = []\n",
    "for index, element in enumerate(points[5:]):\n",
    "    if (index%5)==0:\n",
    "        temp.append(element)\n",
    "\n",
    "\n",
    "coords = np.array(temp)\n",
    "# We create Slices across time and channels in a double for loop\n",
    "temp_for_channel_stacking = []\n",
    "\n",
    "\n",
    "geometry_dict = {}\n",
    "for channel in range(image.shape[4]):\n",
    "    print(f\"Channel {channel}\")\n",
    "\n",
    "    temp_for_time_stacking = []\n",
    "    for t in range(image.shape[3]):\n",
    "        \n",
    "        x = coords[:,0]\n",
    "        y = coords[:,1]\n",
    "        z = coords[:,2]\n",
    "\n",
    "        coords_zyx = np.array([z,y,x]).transpose([1,0])\n",
    "        \n",
    "\n",
    "        #convert the image to SITK (here let's use the intensity for now)\n",
    "        sitk_image = sitk.GetImageFromArray(image[:,:,:,t,channel])\n",
    "\n",
    "        # spline parametrization\n",
    "        #params = [0]# [i / (common_image_shape[2] - 1) for i in range(common_image_shape[2])]\n",
    "        params =  [i / (common_image_shape[2] - 1) for i in range(common_image_shape[2])]\n",
    "        tck, _ = interpolate.splprep(np.swapaxes(coords_zyx, 0, 1), k=3, s=200)\n",
    "\n",
    "        # derivative is tangent to the curve\n",
    "        points = np.swapaxes(interpolate.splev(params, tck, der=0), 0, 1)\n",
    "        Zs = np.swapaxes(interpolate.splev(params, tck, der=1), 0, 1)\n",
    "        direc = np.array(sitk_image.GetDirection()[3:6])\n",
    "        slices = []\n",
    "        orig_frames = []\n",
    "        new_frames = []\n",
    "        phys_sizes = []\n",
    "        new_origins = []\n",
    "        rotation_centers = []\n",
    "        new_sizes = []\n",
    "        rot_matrices = []\n",
    "        orig_spacings = []\n",
    "        orig_directions = []\n",
    "        transforms = []\n",
    "        new_origins_rotated = []\n",
    "        Xs = []\n",
    "        itk_resampled_images = []\n",
    "\n",
    "        for i in range(len(Zs)):\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            # I define the x'-vector as the projection of the y-vector onto the plane perpendicular to the spline\n",
    "            xs = (direc - np.dot(direc, Zs[i]) / (np.power(np.linalg.norm(Zs[i]), 2)) * Zs[i])\n",
    "            \n",
    "\n",
    "            point, Z, X, new_size = points[i], Zs[i], xs, common_image_shape[:2] + [1]\n",
    "            Xs.append(xs)\n",
    "            num_dim = sitk_image.GetDimension()\n",
    "\n",
    "            orig_pixelid = sitk_image.GetPixelIDValue()\n",
    "            orig_direction = sitk_image.GetDirection()\n",
    "            orig_spacing = np.array(sitk_image.GetSpacing())\n",
    "            \n",
    "            new_size = [int(el) for el in new_size]  # SimpleITK expects lists, not ndarrays\n",
    "            point = [float(el) for el in point] # [z,y,x]\n",
    "            \n",
    "\n",
    "            rotation_center = sitk_image.TransformContinuousIndexToPhysicalPoint(point)\n",
    "\n",
    "            X = X / np.linalg.norm(X)\n",
    "            Z = Z / np.linalg.norm(Z)\n",
    "            assert np.dot(X, Z) < 1e-12, 'the two input vectors are not perpendicular!'\n",
    "            Y = np.cross(Z, X)\n",
    "            #[print('orig_direction: ', orig_direction) if i == len(Zs)-1 else None]\n",
    "            orig_frame = np.array(orig_direction).reshape(num_dim, num_dim)\n",
    "            #[print('orig_frame: ', orig_frame) if i == len(Zs)-1 else None]\n",
    "            new_frame = np.array([X, Y, Z])\n",
    "            #[print('new_frame: ', new_frame) if i == len(Zs)-1 else None]\n",
    "\n",
    "            # important: when resampling images, the transform is used to map points from the output image space into the input image space\n",
    "            rot_matrix = np.dot(orig_frame, np.linalg.pinv(new_frame))\n",
    "            transform = sitk.AffineTransform(rot_matrix.flatten(), np.zeros(num_dim), rotation_center)    \n",
    "\n",
    "            phys_size = new_size * orig_spacing\n",
    "            new_origin = rotation_center - phys_size / 2\n",
    "            #[print('new_origin: ', new_origin) if i == len(Zs)-1 else None]\n",
    "\n",
    "            resample_filter = sitk.ResampleImageFilter()\n",
    "            resample_filter.SetSize(new_size)\n",
    "            resample_filter.SetOutputSpacing(orig_spacing)\n",
    "            resample_filter.SetOutputDirection(orig_direction)\n",
    "            resample_filter.SetOutputOrigin(new_origin)\n",
    "            resample_filter.SetInterpolator(sitk.sitkLinear)\n",
    "            resample_filter.SetTransform(transform)\n",
    "            resample_filter.SetDefaultPixelValue(0)\n",
    "\n",
    "            resampled_sitk_image = resample_filter.Execute(sitk_image)\n",
    "            if channel == 0 and t == 0:\n",
    "                geometry_dict[f\"slice_{i}_origin\"] = resampled_sitk_image.GetOrigin()\n",
    "                geometry_dict[f\"slice_{i}_transform\"] = transform\n",
    "\n",
    "            \n",
    "            \n",
    "            np_resampled_sitk_image = sitk.GetArrayFromImage(resampled_sitk_image)\n",
    "            itk_resampled_images.append(resampled_sitk_image)\n",
    "            #[print(np_resampled_sitk_image.shape) if i == len(Zs)-1 else None]\n",
    "            np_resampled_sitk_image = np_resampled_sitk_image.transpose([2,1,0])\n",
    "            #[print(np_resampled_sitk_image.shape) if i == len(Zs)-1 else None]\n",
    "            slices.append(np_resampled_sitk_image)\n",
    "            orig_frames.append(orig_frame)\n",
    "            new_frames.append(new_frame)\n",
    "            phys_sizes.append(phys_size)\n",
    "            new_origins.append(new_origin)\n",
    "            rotation_centers.append(rotation_center)\n",
    "            new_sizes.append(new_size)\n",
    "            rot_matrices.append(rot_matrix)\n",
    "            orig_spacings.append(orig_spacing)\n",
    "            orig_directions.append(orig_direction)\n",
    "            transforms.append(transform)\n",
    "            \n",
    "        # stick slices together\n",
    "        straightened = np.concatenate(slices, axis=2)\n",
    "        \n",
    "        #straightened = interpolate_and_slice(image[:,:,:,t,channel], coords, common_image_shape)\n",
    "        temp_for_time_stacking.append(straightened)\n",
    "\n",
    "    channel_stacked = np.stack(temp_for_time_stacking, axis=-1)\n",
    "    temp_for_channel_stacking.append(channel_stacked)\n",
    "\n",
    "straightened = np.stack(temp_for_channel_stacking, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape before cropping and padding:(36, 36, 64, 23, 4)\n",
      "Image shape after cropping and padding:(32, 32, 64, 24, 4)\n"
     ]
    }
   ],
   "source": [
    "print(\"Image shape before cropping and padding:\" + str(straightened.shape))\n",
    "straightened = crop_or_pad_normal_slices(straightened, end_shape)\n",
    "print(\"Image shape after cropping and padding:\" + str(straightened.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160, 110, 60, 23, 4)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = np.load(img_path)\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The geometric information we need from the initial image does not change with channel or time \n",
    "sitk_image = sitk.GetImageFromArray(image[:,:,:,0,0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us do the back transform for each time step and slice now\n",
    "temp_for_time_stacking = []\n",
    "for t in range(output_reshaped_again.shape[3]):\n",
    "    temp_for_slice_stacking = []\n",
    "    for slice_i in range(output_reshaped_again.shape[2]):\n",
    "        resampled_sitk_image = sitk.GetImageFromArray(output_reshaped_again[:,:,slice_i:slice_i+1,t,0].transpose([2,1,0]))\n",
    "        # You need to set the origin, the direction and the spacing of the resampled image\n",
    "        resampled_sitk_image.SetOrigin(geometry_dict[f\"slice_{slice_i}_origin\"])\n",
    "        resampled_sitk_image.SetDirection((1,0,0,0,1,0,0,0,1))\n",
    "        resampled_sitk_image.SetSpacing((1,1,1))\n",
    "        inverse_transform = geometry_dict[f\"slice_{slice_i}_transform\"].GetInverse()\n",
    "        resampler = sitk.ResampleImageFilter()\n",
    "        resampler.SetSize(sitk_image.GetSize()) # set to original image size\n",
    "        resampler.SetOutputSpacing(sitk_image.GetSpacing()) # set to original image spacing\n",
    "        resampler.SetOutputDirection(sitk_image.GetDirection()) # set to original image direction\n",
    "        resampler.SetOutputOrigin(sitk_image.GetOrigin()) # set to original image origin\n",
    "        resampler.SetInterpolator(sitk.sitkLinear) \n",
    "        resampler.SetTransform(inverse_transform) \n",
    "\n",
    "        resampled_slice = resampler.Execute(resampled_sitk_image) # apply to the resampled slice\n",
    "        resampled_slice = sitk.GetArrayFromImage(resampled_slice)\n",
    "        temp_for_slice_stacking.append(resampled_slice)\n",
    "        \n",
    "    temp_for_time_stacking.append(np.sum(np.array(temp_for_slice_stacking), axis=0))\n",
    "        \n",
    "anomaly_score_4d_image = np.stack(temp_for_time_stacking, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(temp_for_slice_stacking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  White background\n",
    "mlab.figure(bgcolor=(1, 1, 1), size=(800, 800))\n",
    "\n",
    "\n",
    "anomaly_score_color = mlab.contour3d(-anomaly_score_4d_image[...,5], colormap = 'cool', opacity = 0.1)\n",
    "anomaly_score_color = mlab.contour3d(-temp_for_slice_stacking[0], colormap = 'cool', opacity = 0.6)\n",
    "mlab.colorbar(anomaly_score_color, orientation='vertical')\n",
    "mlab.contour3d(-temp_for_slice_stacking[5], colormap = 'cool', opacity = 0.6)\n",
    "mlab.contour3d(-temp_for_slice_stacking[5], colormap = 'cool', opacity = 0.6)\n",
    "mlab.contour3d(-temp_for_slice_stacking[10], colormap = 'cool', opacity = 0.6)\n",
    "mlab.contour3d(-temp_for_slice_stacking[15], colormap = 'cool', opacity = 0.6)\n",
    "mlab.contour3d(-temp_for_slice_stacking[20], colormap = 'cool', opacity = 0.6)\n",
    "mlab.contour3d(-temp_for_slice_stacking[25], colormap = 'cool', opacity = 0.6)\n",
    "mlab.contour3d(-temp_for_slice_stacking[30], colormap = 'cool', opacity = 0.6)\n",
    "mlab.contour3d(-temp_for_slice_stacking[35], colormap = 'cool', opacity = 0.6)\n",
    "mlab.contour3d(-temp_for_slice_stacking[40], colormap = 'cool', opacity = 0.6)\n",
    "mlab.contour3d(-temp_for_slice_stacking[45], colormap = 'cool', opacity = 0.6)\n",
    "mlab.contour3d(-temp_for_slice_stacking[50], colormap = 'cool', opacity = 0.6)\n",
    "mlab.contour3d(-temp_for_slice_stacking[55], colormap = 'cool', opacity = 0.6)\n",
    "mlab.contour3d(-temp_for_slice_stacking[60], colormap = 'cool', opacity = 0.6)\n",
    "\n",
    "\n",
    "mlab.contour3d(segmented[...,0], colormap = 'gray', opacity = 0.3)\n",
    "# Background color should be black\n",
    "\n",
    "#mlab.axes(xlabel='X', ylabel='Y', zlabel='Z') #Display axis\n",
    "# Remove axis\n",
    "mlab.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly_score_4d_image.shape\n",
    "from tvtk.api import tvtk, write_data\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_type = \"patients\" # \"controls\" or \"patients\"\n",
    "images_path = f\"/usr/bmicnas02/data-biwi-01/jeremy_students/data/inselspital/kady/preprocessed/{patient_type}/numpy_velocity_scaled\"\n",
    "segs_path = f\"/usr/bmicnas02/data-biwi-01/jeremy_students/data/inselspital/kady/final_segmentations/{patient_type}\"\n",
    "subject_id = \"208\"\n",
    "image_path = os.path.join(images_path, f\"MACDAVD_{subject_id}_.npy\")\n",
    "seg_path = os.path.join(segs_path, f\"seg_MACDAVD_{subject_id}_.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((160, 110, 56, 15, 4), (160, 110, 56, 24))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.load(image_path).shape ,anomaly_score_4d_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9134607855756806"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anomaly_score_4d_image[...,2].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_slices = np.shape(anomaly_score_4d_image)[3]\n",
    "file_name = \"MACDAVD_208_\"\n",
    "for time_slice in np.arange(time_slices):\n",
    "\n",
    "\n",
    "    # Magnitude\n",
    "\n",
    "    anomaly_score = anomaly_score_4d_image[:,:,:,time_slice]\n",
    "\n",
    "    # X,Y,Z\n",
    "    dim=anomaly_score.shape\n",
    "    # Generate the grid\n",
    "    xx,yy,zz=np.mgrid[0:dim[0],0:dim[1],0:dim[2]]\n",
    "    \n",
    "    pts_anomaly_score = np.empty(anomaly_score.shape + (3,), dtype=int)\n",
    "    pts_anomaly_score[..., 0] = xx\n",
    "    pts_anomaly_score[..., 1] = yy\n",
    "    pts_anomaly_score[..., 2] = zz\n",
    "\n",
    "    pts_anomaly_score = pts_anomaly_score.transpose(2, 1, 0, 3).copy()\n",
    "    pts_anomaly_score.shape = pts_anomaly_score.size // 3, 3\n",
    "    anomaly_score_vec = np.empty(anomaly_score.shape + (1,), dtype=float)\n",
    "    anomaly_score_vec[..., 0] = anomaly_score\n",
    "\n",
    "    anomaly_score_vec = anomaly_score_vec.transpose(2, 1, 0, 3).copy()\n",
    "    \n",
    "    anomaly_score_vec.shape = anomaly_score_vec.size\n",
    "    \n",
    "    \n",
    "    anomaly_score_grid = tvtk.StructuredGrid(dimensions=xx.shape, points=pts_anomaly_score)\n",
    "    anomaly_score_grid.point_data.scalars = anomaly_score_vec\n",
    "    anomaly_score_grid.point_data.scalars.name = 'anomaly_score_intensity'\n",
    "    #anomaly_score_grid.cell_data.scalars = anomaly_score_vec[:-1]\n",
    "    #anomaly_score_grid.cell_data.scalars.name = 'anomaly_score_intensity'\n",
    "    write_data(anomaly_score_grid, os.path.join(\"anomaly_score/\",f\"point_again_{file_name}_anomaly_score_t{time_slice}.vtk\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dimdim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cool it seems to work for the whole thing now let us implement it in the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160, 110, 56)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Below we have an example, now we want for the whole pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check this function!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/bmicnas02/data-biwi-01/jeremy_students/lschlyter/CNN-segmentation/back_transform_utils.py:27: FutureWarning: `selem` is a deprecated argument name for `binary_erosion`. It will be removed in version 1.0. Please use `footprint` instead.\n",
      "  avg = binary_erosion(avg, selem=np.ones((erosion_k, erosion_k,erosion_k)))\n",
      "/usr/bmicnas02/data-biwi-01/jeremy_students/lschlyter/CNN-segmentation/back_transform_utils.py:28: FutureWarning: `selem` is a deprecated argument name for `dilation`. It will be removed in version 1.0. Please use `footprint` instead.\n",
      "  avg = dilation(avg, selem=np.ones((dilation_k, dilation_k,dilation_k)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 3)\n",
      "orig_direction:  (1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0)\n",
      "orig_frame:  [[1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]]\n",
      "new_frame:  [[-0.4140637   0.8540037   0.31500624]\n",
      " [ 0.60547042  0.          0.79586781]\n",
      " [ 0.67967405  0.52026693 -0.51707398]]\n",
      "new_origin:  [ 6.18573314 37.5803668  24.18380119]\n",
      "(1, 36, 36)\n",
      "(36, 36, 1)\n",
      "(36, 36, 64)\n"
     ]
    }
   ],
   "source": [
    "# Shape of the sliced images\n",
    "common_image_shape = [36, 36, 64, 24, 4] # [x, y, z, t, num_channels]\n",
    "\n",
    "image = np.load(img_path)\n",
    "segmented_original = np.load(seg_path)\n",
    "# Enlarge the segmentation slightly to be sure that there are no cutoffs of the aorta\n",
    "time_steps = segmented_original.shape[3]\n",
    "segmented = dilation(segmented_original[:,:,:,3], cube(3))\n",
    "temp_for_stack = [segmented for i in range(time_steps)]\n",
    "segmented = np.stack(temp_for_stack, axis=3)\n",
    "\n",
    "# normalize image to -1 to 1\n",
    "image = normalize_image_new(image)\n",
    "seg_shape = list(segmented.shape)\n",
    "seg_shape.append(image.shape[-1])\n",
    "image_cropped = crop_or_pad_Bern_new(image, seg_shape)\n",
    "temp_images_intensity = image_cropped[:,:,:,:,0] * segmented # change these back if it works\n",
    "temp_images_vx = image_cropped[:,:,:,:,1] * segmented\n",
    "temp_images_vy = image_cropped[:,:,:,:,2] * segmented\n",
    "temp_images_vz = image_cropped[:,:,:,:,3] * segmented\n",
    "\n",
    "## recombine the images\n",
    "image = np.stack([temp_images_intensity,temp_images_vx,temp_images_vy,temp_images_vz], axis=4)\n",
    "cnn_predictions = False\n",
    "\n",
    "\n",
    "\n",
    "if cnn_predictions:\n",
    "    points_ = skeleton_points(segmented_original, dilation_k = 0)\n",
    "    points_dilated = skeleton_points(segmented_original, dilation_k = 4,erosion_k = 4)\n",
    "else:\n",
    "    points_ = skeleton_points(segmented_original, dilation_k = 0)\n",
    "    points_dilated = skeleton_points(segmented_original, dilation_k = 2,erosion_k = 2)\n",
    "points_all = points_dilated.copy()     \n",
    "\n",
    "\n",
    "points = points_all[np.where(points_all[:,1]<60)]\n",
    "points = points[np.where(points[:,0]<90)]\n",
    "\n",
    "\n",
    "# Order the points in ascending order with x\n",
    "points = points[points[:,0].argsort()[::-1]]\n",
    "\n",
    "temp = []\n",
    "for index, element in enumerate(points[5:]):\n",
    "    if (index%5)==0:\n",
    "        temp.append(element)\n",
    "\n",
    "\n",
    "coords = np.array(temp)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "common_image_shape = [36, 36, 64, 24, 4] # [x, y, z, t, num_channels]\n",
    "image_spatial_ex = image[:,:,:,0,0]\n",
    "x = coords[:,0]\n",
    "y = coords[:,1]\n",
    "z = coords[:,2]\n",
    "\n",
    "coords_zyx = np.array([z,y,x]).transpose([1,0])\n",
    "#coords_zyx = np.array([x,y,z]).transpose([1,0])\n",
    "print(coords_zyx.shape)\n",
    "\n",
    "#convert the image to SITK (here let's use the intensity for now)\n",
    "sitk_image = sitk.GetImageFromArray(image_spatial_ex[:,:,:])\n",
    "\n",
    "# spline parametrization\n",
    "#params = [0]# [i / (common_image_shape[2] - 1) for i in range(common_image_shape[2])]\n",
    "params =  [i / (common_image_shape[2] - 1) for i in range(common_image_shape[2])]\n",
    "tck, _ = interpolate.splprep(np.swapaxes(coords_zyx, 0, 1), k=3, s=200)\n",
    "\n",
    "# derivative is tangent to the curve\n",
    "points = np.swapaxes(interpolate.splev(params, tck, der=0), 0, 1)\n",
    "Zs = np.swapaxes(interpolate.splev(params, tck, der=1), 0, 1)\n",
    "direc = np.array(sitk_image.GetDirection()[3:6])\n",
    "#plt.scatter(points[:,2], points[:,1])\n",
    "#plt.scatter(x, y)\n",
    "#plt.show()\n",
    "slices = []\n",
    "orig_frames = []\n",
    "new_frames = []\n",
    "phys_sizes = []\n",
    "new_origins = []\n",
    "rotation_centers = []\n",
    "new_sizes = []\n",
    "rot_matrices = []\n",
    "orig_spacings = []\n",
    "orig_directions = []\n",
    "transforms = []\n",
    "new_origins_rotated = []\n",
    "Xs = []\n",
    "itk_resampled_images = []\n",
    "\n",
    "for i in range(len(Zs)):\n",
    "    \n",
    "    # I define the x'-vector as the projection of the y-vector onto the plane perpendicular to the spline\n",
    "    xs = (direc - np.dot(direc, Zs[i]) / (np.power(np.linalg.norm(Zs[i]), 2)) * Zs[i])\n",
    "    \n",
    "\n",
    "    point, Z, X, new_size = points[i], Zs[i], xs, common_image_shape[:2] + [1]\n",
    "    Xs.append(xs)\n",
    "    num_dim = sitk_image.GetDimension()\n",
    "\n",
    "    orig_pixelid = sitk_image.GetPixelIDValue()\n",
    "    orig_direction = sitk_image.GetDirection()\n",
    "    orig_spacing = np.array(sitk_image.GetSpacing())\n",
    "    \n",
    "    new_size = [int(el) for el in new_size]  # SimpleITK expects lists, not ndarrays\n",
    "    point = [float(el) for el in point] # [z,y,x]\n",
    "    \n",
    "\n",
    "    rotation_center = sitk_image.TransformContinuousIndexToPhysicalPoint(point)\n",
    "\n",
    "    X = X / np.linalg.norm(X)\n",
    "    Z = Z / np.linalg.norm(Z)\n",
    "    assert np.dot(X, Z) < 1e-12, 'the two input vectors are not perpendicular!'\n",
    "    Y = np.cross(Z, X)\n",
    "    [print('orig_direction: ', orig_direction) if i == len(Zs)-1 else None]\n",
    "    orig_frame = np.array(orig_direction).reshape(num_dim, num_dim)\n",
    "    [print('orig_frame: ', orig_frame) if i == len(Zs)-1 else None]\n",
    "    new_frame = np.array([X, Y, Z])\n",
    "    [print('new_frame: ', new_frame) if i == len(Zs)-1 else None]\n",
    "\n",
    "    # important: when resampling images, the transform is used to map points from the output image space into the input image space\n",
    "    rot_matrix = np.dot(orig_frame, np.linalg.pinv(new_frame))\n",
    "    transform = sitk.AffineTransform(rot_matrix.flatten(), np.zeros(num_dim), rotation_center)\n",
    "    #transform = sitk.AffineTransform(np.eye(3).flatten(), np.zeros(num_dim), rotation_center)\n",
    "    #transform = sitk.AffineTransform(rot_matrix.flatten(), np.zeros(num_dim), [0,0,0])\n",
    "\n",
    "    \n",
    "\n",
    "    phys_size = new_size * orig_spacing\n",
    "    new_origin = rotation_center - phys_size / 2\n",
    "    [print('new_origin: ', new_origin) if i == len(Zs)-1 else None]\n",
    "\n",
    "    # Apply rotation on new_origin\n",
    "    #new_origin_rotated = np.dot(rot_matrix, new_origin - rotation_center) + rotation_center\n",
    "\n",
    "    resample_filter = sitk.ResampleImageFilter()\n",
    "    resample_filter.SetSize(new_size)\n",
    "    resample_filter.SetOutputSpacing(orig_spacing)\n",
    "    resample_filter.SetOutputDirection(orig_direction)\n",
    "    resample_filter.SetOutputOrigin(new_origin)\n",
    "    resample_filter.SetInterpolator(sitk.sitkLinear)\n",
    "    resample_filter.SetTransform(transform)\n",
    "    resample_filter.SetDefaultPixelValue(0)\n",
    "\n",
    "    resampled_sitk_image = resample_filter.Execute(sitk_image)\n",
    "    \n",
    "    #sitk_slice, new_size, orig_spacing, orig_direction, orig_frame, new_frame, phys_size, new_origin, rotation_center,rot_matrix, transform = extract_slice_from_sitk_image_extended(sitk_image, points[i], Zs[i], xs, list(common_image_shape[:2]) + [1], fill_value=0)\n",
    "    np_resampled_sitk_image = sitk.GetArrayFromImage(resampled_sitk_image)\n",
    "    itk_resampled_images.append(resampled_sitk_image)\n",
    "    [print(np_resampled_sitk_image.shape) if i == len(Zs)-1 else None]\n",
    "    np_resampled_sitk_image = np_resampled_sitk_image.transpose([2,1,0])\n",
    "    [print(np_resampled_sitk_image.shape) if i == len(Zs)-1 else None]\n",
    "    slices.append(np_resampled_sitk_image)\n",
    "    orig_frames.append(orig_frame)\n",
    "    new_frames.append(new_frame)\n",
    "    phys_sizes.append(phys_size)\n",
    "    new_origins.append(new_origin)\n",
    "    rotation_centers.append(rotation_center)\n",
    "    new_sizes.append(new_size)\n",
    "    rot_matrices.append(rot_matrix)\n",
    "    orig_spacings.append(orig_spacing)\n",
    "    orig_directions.append(orig_direction)\n",
    "    transforms.append(transform)\n",
    "    \n",
    "# stick slices together\n",
    "image_slices = np.concatenate(slices, axis=2)\n",
    "print(image_slices.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "resampled_slices = []\n",
    "for slice_i in np.arange(64):\n",
    "    \n",
    "    resampled_sitk_image = sitk.GetImageFromArray(output_reshaped_again[:,:,slice_i:slice_i+1,0,0].transpose([2,1,0]))\n",
    "    # You need to set the origin, the direction and the spacing of the resampled image\n",
    "    resampled_sitk_image.SetOrigin(itk_resampled_images[slice_i].GetOrigin())\n",
    "    resampled_sitk_image.SetDirection(itk_resampled_images[slice_i].GetDirection())\n",
    "    resampled_sitk_image.SetSpacing(itk_resampled_images[slice_i].GetSpacing())\n",
    "    inverse_transform = transforms[slice_i].GetInverse()\n",
    "    resampler = sitk.ResampleImageFilter()\n",
    "    resampler.SetSize(sitk_image.GetSize()) # set to original image size\n",
    "    resampler.SetOutputSpacing(sitk_image.GetSpacing()) # set to original image spacing\n",
    "    resampler.SetOutputDirection(sitk_image.GetDirection()) # set to original image direction\n",
    "    resampler.SetOutputOrigin(sitk_image.GetOrigin()) # set to original image origin\n",
    "    resampler.SetInterpolator(sitk.sitkLinear) \n",
    "    resampler.SetTransform(inverse_transform) \n",
    "\n",
    "    resampled_slice = resampler.Execute(resampled_sitk_image) # apply to the resampled slice\n",
    "    resampled_slice = sitk.GetArrayFromImage(resampled_slice)\n",
    "    resampled_slices.append(resampled_slice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(144, 112, 40)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bascially now you have 64 times the orginial image where for each it corresponds to the anomaly score of the slice\n",
    "# So we just sum across the 64 images to get the anomaly score for the whole image\n",
    "anomaly_score_image = np.sum(np.array(resampled_slices), axis=0)\n",
    "anomaly_score_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlab.figure()\n",
    "\n",
    "\n",
    "anomaly_score_color = mlab.contour3d(anomaly_score_image, colormap = 'cool', opacity = 0.1)\n",
    "mlab.colorbar(anomaly_score_color, orientation='vertical')\n",
    "mlab.contour3d(segmented[...,0], colormap = 'gray', opacity = 0.1)\n",
    "mlab.axes(xlabel='X', ylabel='Y', zlabel='Z') #Display axis\n",
    "mlab.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
